# modelo-de-classificacao-de-reviews
[Projeto pessoa] IA capaz de ler reviews de um csv do Kaggle e dizer quais s√£o positivas, quais s√£o negativas e o motivo.

Como testar ambos os algoritmos?

1. Clonar o reposit√≥rio.
2. Rodar "pip install requirements.txt" no terminal da IDE.
3. Rodar "python3 modelo.py" 

üìå Projeto de Classifica√ß√£o de Textos

Este projeto tem como objetivo desenvolver um modelo de classifica√ß√£o autom√°tica de textos de review, explorando diferentes algoritmos de aprendizado de m√°quina e t√©cnicas de pr√©-processamento, nesse caso, Naive Bayes e Regress√£o Log√≠stica. O foco foi avaliar o desempenho de modelos cl√°ssicos em NLP (Processamento de Linguagem Natural) e apontar se a review foi realmente positiva ou negativa.

üöÄ Racioc√≠nio e Escolhas T√©cnicas
1. Representa√ß√£o dos dados (TF-IDF)

Para transformar os textos em representa√ß√µes num√©ricas, utilizei o TF-IDF Vectorizer, que avalia a relev√¢ncia de cada termo em um documento em rela√ß√£o ao corpus. Essa escolha foi feita porque o TF-IDF reduz a influ√™ncia de palavras muito comuns e destaca termos mais discriminativos, sendo mais eficiente que a simples contagem de palavras.

2. Modelos de classifica√ß√£o testados

Naive Bayes (MultinomialNB): escolhido como baseline, pois √© um algoritmo r√°pido, simples e tradicionalmente eficaz em classifica√ß√£o de textos. Apesar de suas limita√ß√µes (assume independ√™ncia entre features), fornece uma boa refer√™ncia inicial de desempenho e contrap√µe bem o algoritmo de regress√£o log√≠stica, focada em definir pesos e saber rela√ß√µes entre palavras.

Regress√£o Log√≠stica: selecionada por ser um modelo mais robusto e interpret√°vel, que aprende pesos para cada feature sem assumir independ√™ncia entre elas, diferentemente do Naive Bayes. Em bases de dados maiores, tende a superar o Naive Bayes em precis√£o e recall. Nos resultados com 1000 itera√ß√µes, tive como reaultado que a regress√£o log√≠stica funcionou melhor.

3. Divis√£o dos dados

Utilizei o train_test_split do scikit-learn para separar os dados em treino e teste, garantindo a avalia√ß√£o justa dos modelos.

4. M√©tricas de avalia√ß√£o

Adotei o F1-score como principal m√©trica de an√°lise, por ser mais adequada em casos de classes desbalanceadas, j√° que combina precis√£o e recall, bem como a support para saber a volumetria dos dados. Al√©m disso, usei o classification_report para detalhar o desempenho por classe.

5. Tratamento do desbalanceamento de classes

O dataset apresentou forte desbalanceamento, o que resultava em baixo desempenho para a classe minorit√°ria. Para corrigir isso, utilizei o par√¢metro class_weight='balanced' na Regress√£o Log√≠stica. Essa t√©cnica ajusta o peso das classes na fun√ß√£o de custo, permitindo que o modelo d√™ mais aten√ß√£o √†s classes menos representadas.

Essa decis√£o foi crucial para melhorar o F1-score dos exemplos negativos, que inicialmente estava insatisfat√≥rio (abaixo de 70%).

üõ†Ô∏è Tecnologias Utilizadas

Python como linguagem principal.
Pandas para manipula√ß√£o de dados.
scikit-learn para vetoriza√ß√£o de texto, implementa√ß√£o dos modelos e m√©tricas de avalia√ß√£o.

üìä Conclus√µes

O Naive Bayes cumpriu bem seu papel como baseline, mas apresentou limita√ß√µes na classe minorit√°ria.

A Regress√£o Log√≠stica com balanceamento por peso trouxe ganhos significativos em recall e F1-score, mostrando-se a melhor abordagem para este problema e o uso do TF-IDF foi fundamental para destacar palavras relevantes e melhorar a qualidade da representa√ß√£o textual.

Principais reclama√ß√µes incluem termos que referenciam a log√≠stica de entrega dos produtos e se o que queriam chegou.
